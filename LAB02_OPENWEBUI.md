# LAB02 OpenWebUI Integration

## Hva er OpenWebUI?

OpenWebUI er en moderne, brukervennlig webgrensesnitt for AI-chatbots som gir en ChatGPT-lignende opplevelse. Det er en √•pen kildekode-l√∏sning som kan brukes med forskjellige AI-modeller og API-er.

### Hovedfunksjoner:
- üé® Moderne og intuitiv chat-grensesnitt
- üí¨ St√∏tte for samtalehistorikk
- üîß Konfigurerbar og tilpassbar
- üîå API-integrasjon med ulike AI-tjenester
- üì± Responsiv design for desktop og mobil

## Implementering i LAB02

OpenWebUI er lagt til som en egen Docker-tjeneste i `docker-compose.yml`:

```yaml
openwebui:
  image: ghcr.io/open-webui/open-webui:latest
  ports:
    - "8002:8002"
  volumes:
    - openwebui:/app/backend/data
```

### Konfigurasjonsdetaljer:
- **Image**: Bruker den offisielle OpenWebUI Docker-imaget
- **Port**: Eksponert p√• port 8002 for √• unng√• konflikter med andre tjenester
- **Persistent Storage**: Data lagres i `openwebui` volume for √• bevare samtaler og innstillinger

### Tilgang:
- **URL**: http://localhost:8002
- **Integrasjon**: Kan konfigureres til √• bruke v√•r travel-weather-agent via API

## Fordeler med OpenWebUI

1. **Bedre brukeropplevelse**: Mer polert grensesnitt enn v√•r enkle web-tjeneste
2. **Samtalehistorikk**: Automatisk lagring og gjenoppretting av samtaler
3. **Konfigurerbarhet**: Kan tilpasses for spesifikke bruksomr√•der
4. **Skalerbarhet**: Enkel √• utvide med nye funksjoner og integrasjoner

## Integrasjon med LAB02 Backend

OpenWebUI kan integreres p√• to m√•ter med v√•r eksisterende arkitektur:

### Alternativ 1: Kobling via Agent API (Port 8001)

OpenWebUI kan konfigureres til √• kommunisere med travel-weather-agent som fungerer som en AI-proxy:

```bash
# Konfigurer OpenWebUI til √• bruke agent som AI-backend
# I OpenWebUI admin panel:
# API Base URL: http://travel-agent:8001
# API Type: OpenAI Compatible
```

**Fordeler:**
- Direkte tilgang til AI-funksjonalitet med v√¶rverkt√∏y
- Samtalehukommelse h√•ndteres av agenten
- Ingen ekstra konfigurering av MCP protocol

### Alternativ 2: Direkte kobling med MCP Server (Port 8000) ‚≠ê

Den mest kraftige l√∏sningen er √• koble OpenWebUI direkte til MCP serveren:

```bash
# Konfigurer OpenWebUI til √• bruke MCP server
# I OpenWebUI admin panel:
# API Base URL: http://mcp-server:8000
# OpenAPI Spec URL: http://mcp-server:8000/openapi.json
```

**Hvorfor OpenAPI-st√∏tte er en styrke:**

üîß **Automatisk verkt√∏yoppdagelse**: OpenWebUI kan automatisk lese OpenAPI-spesifikasjonen fra `http://mcp-server:8000/openapi.json` og oppdage alle tilgjengelige verkt√∏y (weather, ping, status) uten manuell konfigurering.

üìù **Dynamisk dokumentasjon**: OpenAPI-spec gir komplett dokumentasjon av alle endpoints, parametere og returformater - OpenWebUI kan vise dette til brukerne.

üîÑ **Automatisk oppdatering**: N√•r nye verkt√∏y legges til MCP serveren, oppdateres OpenAPI-spec automatisk, og OpenWebUI f√•r tilgang til nye funksjoner uten restart.

‚ö° **Optimal ytelse**: Direkte kommunikasjon med MCP server eliminerer ett lag (agent) og gir raskere respons.

üõ†Ô∏è **Full MCP Protocol st√∏tte**: OpenWebUI kan utnytte alle MCP-funksjoner direkte, inkludert fremtidige utvidelser.

### Sammenligning: Agent vs MCP Server Integration

| Aspekt | Agent API (Port 8001) | MCP Server (Port 8000) |
|--------|----------------------|------------------------|
| **Arkitektur** | OpenWebUI ‚Üí Agent ‚Üí MCP ‚Üí External APIs | OpenWebUI ‚Üí MCP ‚Üí External APIs |
| **Kompleksitet** | H√∏yere (flere lag) | Lavere (f√¶rre lag) |
| **Latens** | H√∏yere (ekstra hop via agent) | Lavere (direkte til MCP) |
| **AI-integrasjon** | Innebygd OpenAI-funksjonalitet | Kun verkt√∏y/tools |

#### Alternativ 1: Agent API (Port 8001)

**‚úÖ Fordeler:**
- **AI-behandling inkludert**: Agent h√•ndterer b√•de AI-respons og verkt√∏ykall
- **Samtalehukommelse**: Innebygd session management i agenten
- **Komplett l√∏sning**: √ân endpoint for alt (AI + tools)
- **Enklere frontend**: OpenWebUI trenger kun √• sende tekst og motta svar
- **Robust error handling**: Agent kan h√•ndtere feil og gi brukervennlige meldinger

**‚ùå Ulemper:**
- **Ekstra latens**: Request m√• g√• gjennom agent-laget
- **Begrenset fleksibilitet**: Bundet til agent's AI-modell og logikk
- **Avhengighet**: Hvis agent feiler, blir hele systemet utilgjengelig
- **Ressursbruk**: Agent m√• kj√∏re kontinuerlig selv for enkle verkt√∏ykall

#### Alternativ 2: MCP Server (Port 8000)

**‚úÖ Fordeler:**
- **Optimal ytelse**: Direkte kommunikasjon, minimale lag
- **Maksimal fleksibilitet**: OpenWebUI kan bruke sin egen AI-logikk
- **Skalerbarhet**: MCP server er lett og rask
- **OpenAPI-integrasjon**: Automatisk verkt√∏yoppdagelse og dokumentasjon
- **Fremtidssikker**: St√∏tter full MCP protocol
- **Modul√¶rt design**: Verkt√∏y kan utvikles og deployes uavhengig

**‚ùå Ulemper:**
- **Kun verkt√∏y**: Ingen innebygd AI - OpenWebUI m√• h√•ndtere AI-delen
- **Mer konfigurasjon**: Krever setup av AI-modell i OpenWebUI
- **Sammensatt arkitektur**: OpenWebUI m√• orkestrere AI + verkt√∏ykall
- **Ingen samtalehukommelse**: MCP server lagrer ikke session state

### Anbefaling basert p√• bruksomr√•de:

**Velg Agent API (8001) hvis:**
- Du vil ha en "plug-and-play" l√∏sning
- Enkel konfigurasjon er viktigst
- Du trenger kun grunnleggende chat-funksjonalitet

**Velg MCP Server (8000) hvis:**
- Ytelse og skalerbarhet er kritisk
- Du vil ha full kontroll over AI-modell og -logikk
- Du planlegger √• utvide med mange flere verkt√∏y
- Du vil utnytte OpenWebUI's avanserte funksjoner fullt ut

### Anbefalt arkitektur:

```
OpenWebUI (Port 8002) 
    ‚Üì OpenAPI integration
MCP Server (Port 8000)
    ‚Üì Tool endpoints
External APIs (Weather, etc.)
```

Dette gir oss det beste fra begge verdener:
- Robust backend-arkitektur med MCP protocol
- Moderne, brukervennlig frontend med OpenWebUI
- Automatisk verkt√∏yoppdagelse via OpenAPI
- Optimal ytelse og fleksibilitet